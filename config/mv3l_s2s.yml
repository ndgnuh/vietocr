# change to list chars of your dataset or use default vietnamese chars
vocab: 'aAàÀảẢãÃáÁạẠăĂằẰẳẲẵẴắẮặẶâÂầẦẩẨẫẪấẤậẬbBcCdDđĐeEèÈẻẺẽẼéÉẹẸêÊềỀểỂễỄếẾệỆfFgGhHiIìÌỉỈĩĨíÍịỊjJkKlLmMnNoOòÒỏỎõÕóÓọỌôÔồỒổỔỗỖốỐộỘơƠờỜởỞỡỠớỚợỢpPqQrRsStTuUùÙủỦũŨúÚụỤưƯừỪửỬữỮứỨựỰvVwWxXyYỳỲỷỶỹỸýÝỵỴzZ0123456789!"#$%&''()*+,-./:;<=>?@[\]^_`{|}~ '

backbone: mobilenet_v3_large
cnn:
  dropout: 0.1
  output_size: 256

seq_modeling: seq2seq
transformer:
    encoder_hidden: 256
    decoder_hidden: 256
    img_channel: 256
    decoder_embedded: 256
    dropout: 0.1
    sos_token_id: 1

optimizer:
    max_lr: 0.001
    pct_start: 0.1

trainer:
    batch_size: 16
    print_every: 500
    valid_every: 4000
    iters: 1_000_000
    # where to save our model for prediction
    export: ./weights/mv3l_s2s.pth
    checkpoint: ./checkpoint/mv3l_s2s.pth
    log: ./train_mv3l_s2s.log
    # null to disable compuate accuracy, or change to number of sample to enable validiation while training
    metrics: null

lmdb_cache_path: data-cache
dataset:    
    # name of your dataset
    name: vietocr_data
    # path to annotation and image
    data_root: data/vietocr-dataset
    train_annotation: train.txt
    valid_annotation: val.txt
    # resize image to 32 height, larger height will increase accuracy
    image_height: 32
    image_min_width: 32
    image_max_width: 512
