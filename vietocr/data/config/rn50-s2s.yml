backbone: resnet
cnn:
  output_size: 256
  dropout: 0.1
  # arch: resnet18
  # arch: resnet34
  arch: resnet50
  # arch: resnet101
  # arch: resnet152
  # arch: wide_resnet50_2
  # arch: wide_resnet101_2

seq_modeling: seq2seq
transformer:
    encoder_hidden: 256
    decoder_hidden: 256
    img_channel: 256
    decoder_embedded: 256
    dropout: 0.1
    sos_token_id: 1

optimizer:
    max_lr: 0.001
    pct_start: 0.1


trainer:
    batch_size: 32
    print_every: 200
    valid_every: 4000
    iters: 1_000_000 # Just loop for a very long time
    # where to save our model for prediction
    export: ./weights/rn50_s2s.pth
    checkpoint: ./checkpoint/rn50_s2s.pth
    log: ./rn50_s2s.log
    # null to disable compuate accuracy, or change to number of sample to enable validiation while training
    metrics: null

lmdb_cache_path: data-cache
dataset:    
    # name of your dataset
    name: dict_02
    # path to annotation and image
    data_root: data/dict_02/
    train_annotation: train.txt
    valid_annotation: val.txt
    # resize image to 32 height, larger height will increase accuracy
    image_height: 32
    image_min_width: 32
    image_max_width: 512

dataloader:
    num_workers: 6
    pin_memory: True


