backbone: shufflenet
cnn:
  output_size: 256
  dropout: 0.1
  # arch: shufflenet_v2_x0_5
  arch: shufflenet_v2_x2_0
  # arch: shufflenet_v2_x1_5
  # arch: shufflenet_v2_x2_0

seq_modeling: seq2seq
transformer:
    encoder_hidden: 256
    decoder_hidden: 256
    img_channel: 256
    decoder_embedded: 256
    dropout: 0.1

optimizer:
    max_lr: 0.001
    pct_start: 0.1

trainer:
    batch_size: 32
    print_every: 500
    valid_every: 4000
    iters: 1_000_000
    # where to save our model for prediction
    export: ./weights/shufflenet_v2_x2_0_s2s.pth
    checkpoint: ./checkpoint/shufflenet_v2_x2_0_s2s.pth
    log: ./shufflenet_v2_x2_0_s2s.log
    # null to disable compuate accuracy, or change to number of sample to enable validiation while training
    metrics: null

lmdb_cache_path: data-cache
dataset:    
    # name of your dataset
    name: vietocr_data
    # path to annotation and image
    data_root: data/vietocr-dataset
    train_annotation: train.txt
    valid_annotation: val.txt
    # resize image to 32 height, larger height will increase accuracy
    image_height: 32
    image_min_width: 64
    image_max_width: 512
